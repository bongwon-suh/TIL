### Tensorflow Mechanics

1. Build graph using TensorFlow operations
2. feed data and run graph
3. update variables in the graph

```python
node1 = tf.constant(3.0, tf.float32)
node2 = tf.constant(4.0)
node3 = node1 + node2

sess=tf.Session()
print("sess.run(node1, node2):", sess.run([node1, node2]))
print("sess.run(node3) : ", sess.run(node3))
```

sess.run(node1, node2) : [3.0, 4.0]
sess.run(node3) : 7.0



### Placeholder

 It is simply a variable that we will assign data to at a later date.

It allows us to create our operations and build our computation graph, without needing the data. 

```python
a = tf.placeholder(tf.float32)
b = tf.placeholder(tf.float32)
adder_node = a + b
print(sess.run(adder_node, feed_dict={a:3, b:4.5}))
print(sess.run(adder_node, feed_dict={a:[1,3], b:[2,4]}))
```

7.5
[3. 7.]



### Tensor Ranks, Shapes and Types

| Rank | Shapes       | Math entity | Python example                            |
| ---- | ------------ | ----------- | ----------------------------------------- |
| 0    | []           | Scalar      | s = 483                                   |
| 1    | [D0]         | Vector      | v  = [1.2, 2.2, 3.3]                      |
| 2    | [D0, D1]     | Matrix      | m = [[1,2,3], [4,5,6]]                    |
| 3    | [D0, D1, D2] | 3-Tensor    | t = [ [ [1], [2], [3] ],[ [4],[5],[6] ] ] |
| n    | .....        | n-Tensor    | ...                                       |



| Data Type | Python Type |
| --------- | ----------- |
| DT_FLOAT  | tf.float32  |
| DT_DOUBLE | tf.float64  |
| DT_INT8   | tf.int8     |
| DT_INT16  | tf.int16    |
| DT_INT32  | tf.int32    |
| DT_INT64  | tf.int64    |



### Linear Regression

- Linear Regression은 주어진 데이터를 나타내는 최적의 직선을 찾아내는 과정
- 주어진 x에 대해서 가설 H(hypothesis)을 세우고 가중치 W(weight), 편향 b(bias)의 가장 적합한 값을 찾는과정

#####	Hypothesis

$$
H(x)=Wx+b
$$

##### Cost function

$$
\cos t\left(W,b\right)\ =\ \frac{1}{m}\sum _{i=1}^m{\left(H\left(x^{\left(i\right)}\right)\ -\ {y}^{\left(i\right)}\right)}^2
$$



``` python
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()

X = tf.placeholder(tf.float32, shape=[None])
Y = tf.placeholder(tf.float32, shape=[None])
W = tf.Variable(tf.random_normal([1]), name='weight')
b = tf.Variable(tf.random_normal([1]), name='bias')

hypothesis = X * W + b

# cost function
cost = tf.reduce_mean(tf.square(hypothesis - Y))

# minimize
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)
train = optimizer.minimize(cost)

sess = tf.Session()
sess.run(tf.global_variables_initializer())

for step in range(2001):
    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train], feed_dict={X:[1,2,3,4,5], Y:[1,2,3,4,5]})
    if step % 20 == 0:
        print(step, cost_val, W_val, b_val)

print(sess.run(hypothesis, feed_dict={X: [8,9,10]}))
```

1960 2.1118944e-07 [0.99970263] [0.00107344]
1980 1.8437416e-07 [0.99972206] [0.00100319]
2000 1.6103792e-07 [0.9997403] [0.00093753]
[7.99886  8.9986   9.998341]